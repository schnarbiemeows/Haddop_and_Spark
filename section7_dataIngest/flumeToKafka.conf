# sdc.conf: A multiplex flume configuration
# Source: log file
# Sink 1: Unprocessed data to HDFS
# Sink 2: Spark

# Name the components on this agent
sdc.sources = ws
sdc.sinks = kafka
sdc.channels = mem

# Describe/configure the source
sdc.sources.ws.type = exec
sdc.sources.ws.command = tail -F /opt/gen_logs/logs/access.log

# Describe the sink
sdc.sinks.kafka.type = org.apache.flume.sink.kafka.KafkaSink
sdc.sinks.kafka.brokerList = nn01.itversity.com:6667,nn02.itversity.com:6667,rm01.itversity.com:6667
sdc.sinks.kafka.topic = kafkademoschnarbs


# Use a channel sdcich buffers events in memory
sdc.channels.mem.type = memory
sdc.channels.mem.capacity = 1000
sdc.channels.mem.transactionCapacity = 100


# Bind the source and sink to the channel
sdc.sources.ws.channels = mem
sdc.sinks.kafka.channel = mem